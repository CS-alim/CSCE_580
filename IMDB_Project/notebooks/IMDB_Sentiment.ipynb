{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdb39979",
   "metadata": {},
   "source": [
    "IMDB Sentiment Classification Project CSCE 580 - Fall 2025\n",
    "\n",
    "Models Compared\n",
    "- Fine tuned DistilBERT\n",
    "- base DistilBERT\n",
    "- Classical ML\n",
    "- GPT 2 prompt based classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0503f041",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install if needed\n",
    "# !pip install transformers torch scikit-learn pandas numpy matplotlib seaborn\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification, \n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    ")\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\" Using device: {device}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5867c67",
   "metadata": {},
   "source": [
    "Section 1: Load and Split Dataset\n",
    "\n",
    "We load the IMDB CSV from the 'data' folder, encode sentiments as 0 or 1, then create train, validation, and test splits using stratifies sampling to preserve label balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f082673",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/IMDB Dataset.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(df.head())\n",
    "print(df[\"sentiment\"].value_counts())\n",
    "\n",
    "\n",
    "# Encode labels: Positive -> 1, Negative -> 0\n",
    "label_map = {\"positive\": 1, \"negative\": 0}\n",
    "df[\"label\"] = df[\"sentiment\"].map(label_map)\n",
    "\n",
    "\n",
    "X = df[\"review\"].values\n",
    "y = df[\"label\"].values\n",
    "\n",
    "\n",
    "#Train + val vs test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y,\n",
    ")\n",
    "#Train vs validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=y_temp,\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(X_train)}, Val size: {len(X_val)}, Test size: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d264e4b2",
   "metadata": {},
   "source": [
    "Section 2: Preprocessing for DistilBERT\n",
    "\n",
    "We use the 'distilbert-base-uncased' tokenizer.\n",
    "Reviews are tokenized, truncated or padded to a fixed max length, and wrapped into a custom PyTorch 'Dataset'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5c60e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "\n",
    "MAX_LEN = 256\n",
    "\n",
    "\n",
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=256):\n",
    "        self.texts = list(texts)\n",
    "        self.labels = list(labels)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = int(self.labels[idx])\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "\n",
    "train_dataset = IMDBDataset(X_train, y_train, tokenizer, MAX_LEN)\n",
    "val_dataset = IMDBDataset(X_val, y_val, tokenizer, MAX_LEN)\n",
    "test_dataset = IMDBDataset(X_test, y_test, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf02ce72",
   "metadata": {},
   "source": [
    "Section 3: Fine-tuning DistilBERT\n",
    "\n",
    "We fine tune `distilbert-base-uncased` for binary sentiment classification using the Hugging Face Trainer API.  \n",
    "We track accuracy, precision, recall, and F1 during evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd351bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=2,\n",
    ")\n",
    "fine_tuned_model.to(device)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 3\n",
    "LR = 2e-5\n",
    "\n",
    "output_dir = \"../models/distilbert_finetuned_imdb\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=LR,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_dir=\"../logs\",\n",
    "    logging_steps=100,\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average=\"binary\", zero_division=0\n",
    "    )\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=fine_tuned_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "train_result = trainer.train()\n",
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54616648",
   "metadata": {},
   "source": [
    "Section 4: Plot and Accuracy and Loss Curves\n",
    "\n",
    "We inspect training and validation loss and validation accuracy over steps.  \n",
    "This helps comment on convergence and possible overfitting in the report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac749300",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = pd.DataFrame(trainer.state.log_history)\n",
    "display(logs.tail())\n",
    "\n",
    "train_loss = logs[logs[\"loss\"].notna()]\n",
    "eval_loss  = logs[logs[\"eval_loss\"].notna()]\n",
    "eval_acc   = logs[logs[\"eval_accuracy\"].notna()]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_loss[\"step\"], train_loss[\"loss\"], label=\"Train loss\")\n",
    "plt.plot(eval_loss[\"step\"],  eval_loss[\"eval_loss\"], label=\"Val loss\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Fine tuned DistilBERT loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(eval_acc[\"step\"], eval_acc[\"eval_accuracy\"], label=\"Val accuracy\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Fine tuned DistilBERT validation accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee0ad0d",
   "metadata": {},
   "source": [
    "Section 5: Evaluation of fine tuned DistilBERT\n",
    "\n",
    "We evaluate the fine tuned model on the held out test set and record accuracy, precision, recall, F1, and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1414f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_ft = trainer.predict(test_dataset)\n",
    "test_logits_ft = predictions_ft.predictions\n",
    "y_pred_ft = np.argmax(test_logits_ft, axis=-1)\n",
    "\n",
    "print(\"Fine tuned DistilBERT test accuracy:\",\n",
    "      accuracy_score(y_test, y_pred_ft))\n",
    "print(classification_report(y_test, y_pred_ft, target_names=[\"negative\", \"positive\"]))\n",
    "\n",
    "cm_ft = confusion_matrix(y_test, y_pred_ft)\n",
    "cm_ft\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09d0789",
   "metadata": {},
   "source": [
    "Section 6: Base DistilBERT without fine tuning\n",
    "\n",
    "We load the base DistilBERT model with a classification head but without training on the IMDB data.  \n",
    "This acts as the base transformer comparison in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750409da",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=2,\n",
    ")\n",
    "base_model.to(device)\n",
    "\n",
    "base_trainer = Trainer(\n",
    "    model=base_model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"../models/distilbert_base_imdb\",\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "    ),\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "base_predictions = base_trainer.predict(test_dataset)\n",
    "base_logits = base_predictions.predictions\n",
    "y_pred_base = np.argmax(base_logits, axis=-1)\n",
    "\n",
    "print(\"Base DistilBERT test accuracy:\",\n",
    "      accuracy_score(y_test, y_pred_base))\n",
    "print(classification_report(y_test, y_pred_base, target_names=[\"negative\", \"positive\"]))\n",
    "\n",
    "cm_base = confusion_matrix(y_test, y_pred_base)\n",
    "cm_base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b191b5e",
   "metadata": {},
   "source": [
    "Section 7: Classical machine learning baseline\n",
    "\n",
    "We build a baseline model using TF IDF features and Logistic Regression.  \n",
    "This is our classical statistical model for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a371bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words=\"english\",\n",
    ")\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf   = vectorizer.transform(X_val)\n",
    "X_test_tfidf  = vectorizer.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "\n",
    "start_train_clf = time.time()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "train_time_clf = time.time() - start_train_clf\n",
    "\n",
    "start_infer_clf = time.time()\n",
    "y_pred_clf = clf.predict(X_test_tfidf)\n",
    "infer_time_clf = time.time() - start_infer_clf\n",
    "\n",
    "print(\"Classical model (LogReg) test accuracy:\",\n",
    "      accuracy_score(y_test, y_pred_clf))\n",
    "print(classification_report(y_test, y_pred_clf, target_names=[\"negative\", \"positive\"]))\n",
    "\n",
    "cm_clf = confusion_matrix(y_test, y_pred_clf)\n",
    "cm_clf\n",
    "\n",
    "print(f\"Classical train time: {train_time_clf:.2f} s\")\n",
    "print(f\"Classical inference time on test: {infer_time_clf:.2f} s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ac6e8e",
   "metadata": {},
   "source": [
    "Section 8: GPT 2 prompt based classification\n",
    "\n",
    "We use a GPT style causal language model (`openai-community/gpt2`) as a sentiment classifier using prompts.  \n",
    "To keep runtime reasonable, we evaluate on a subset of the test set.  \n",
    "We then compute accuracy, precision, recall, F1, and a confusion matrix for that subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3afbe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_MODEL_NAME = \"openai-community/gpt2\"\n",
    "\n",
    "gpt_tokenizer = AutoTokenizer.from_pretrained(GPT_MODEL_NAME)\n",
    "gpt_model = AutoModelForCausalLM.from_pretrained(GPT_MODEL_NAME).to(device)\n",
    "\n",
    "# GPT 2 does not have a pad token by default, so we reuse eos token\n",
    "if gpt_tokenizer.pad_token is None:\n",
    "    gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n",
    "\n",
    "gpt_model.eval()\n",
    "\n",
    "def classify_with_gpt2(review, max_new_tokens=8):\n",
    "    \"\"\"\n",
    "    Simple prompt based sentiment classification using GPT 2.\n",
    "    It looks for the words 'positive' or 'negative' in the generated continuation.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"You are a sentiment classifier. \"\n",
    "        \"Decide whether the following movie review is Positive or Negative.\\n\\n\"\n",
    "        f\"Review: {review}\\n\"\n",
    "        \"Sentiment:\"\n",
    "    )\n",
    "\n",
    "    inputs = gpt_tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = gpt_model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "            pad_token_id=gpt_tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    generated = gpt_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    tail = generated.split(\"Sentiment:\")[-1].strip().lower()\n",
    "\n",
    "    if \"positive\" in tail:\n",
    "        return 1\n",
    "    if \"negative\" in tail:\n",
    "        return 0\n",
    "\n",
    "    # fallback guess\n",
    "    return 1\n",
    "\n",
    "# Evaluate GPT 2 on a subset of the test set for speed\n",
    "N_GPT_TEST = 300  # you can adjust this if it is too slow\n",
    "X_test_sub = X_test[:N_GPT_TEST]\n",
    "y_test_sub = y_test[:N_GPT_TEST]\n",
    "\n",
    "gpt_preds = []\n",
    "start_gpt = time.time()\n",
    "for text in X_test_sub:\n",
    "    gpt_preds.append(classify_with_gpt2(text))\n",
    "gpt_infer_time = time.time() - start_gpt\n",
    "\n",
    "gpt_preds = np.array(gpt_preds)\n",
    "\n",
    "print(\"GPT 2 subset test accuracy:\",\n",
    "      accuracy_score(y_test_sub, gpt_preds))\n",
    "print(classification_report(y_test_sub, gpt_preds, target_names=[\"negative\", \"positive\"]))\n",
    "\n",
    "cm_gpt = confusion_matrix(y_test_sub, gpt_preds)\n",
    "cm_gpt\n",
    "\n",
    "print(f\"GPT 2 inference time on {N_GPT_TEST} samples: {gpt_infer_time:.2f} s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511026fe",
   "metadata": {},
   "source": [
    "Section 9: Confusion matrices and metrics comparison\n",
    "\n",
    "We plot confusion matrices for all models and build a summary table with accuracy, precision, recall, and F1.  \n",
    "For GPT 2 the metrics are based on the evaluated subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdef19ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(cm, title):\n",
    "    plt.figure()\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=[\"negative\", \"positive\"],\n",
    "        yticklabels=[\"negative\", \"positive\"],\n",
    "    )\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "plot_cm(cm_ft,   \"Fine tuned DistilBERT confusion matrix\")\n",
    "plot_cm(cm_base, \"Base DistilBERT confusion matrix\")\n",
    "plot_cm(cm_clf,  \"Classical LogReg confusion matrix\")\n",
    "plot_cm(cm_gpt,  \"GPT 2 confusion matrix (subset)\")\n",
    "\n",
    "def get_metrics(y_true, y_pred, name):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"binary\", zero_division=0\n",
    "    )\n",
    "    return {\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1\": f1,\n",
    "    }\n",
    "\n",
    "rows = []\n",
    "rows.append(get_metrics(y_test,     y_pred_ft,   \"Fine tuned DistilBERT\"))\n",
    "rows.append(get_metrics(y_test,     y_pred_base, \"Base DistilBERT\"))\n",
    "rows.append(get_metrics(y_test,     y_pred_clf,  \"Classical Logistic Regression\"))\n",
    "rows.append(get_metrics(y_test_sub, gpt_preds,   \"GPT 2 (subset)\"))\n",
    "\n",
    "metrics_df = pd.DataFrame(rows)\n",
    "metrics_df\n",
    "metrics_df.to_csv(\"../results/model_metrics.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacd70bd",
   "metadata": {},
   "source": [
    "Section 10: AI test cases\n",
    "\n",
    "We define a small set of custom reviews with known sentiment and run all four models on each.  \n",
    "These results can be copied into the AI testcase template in the project guidelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de857551",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    \"This movie was amazing. The acting was brilliant and I loved every minute of it.\",\n",
    "    \"I really wanted to enjoy this film but it was boring and way too long.\",\n",
    "    \"The visuals were impressive but the story was confusing and the characters were flat.\",\n",
    "]\n",
    "\n",
    "def predict_with_distilbert(model, text):\n",
    "    encoded = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=MAX_LEN,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**encoded).logits\n",
    "    pred = int(torch.argmax(logits, dim=-1).cpu().item())\n",
    "    return pred  # 1 positive, 0 negative\n",
    "\n",
    "def predict_with_classical(text):\n",
    "    vec = vectorizer.transform([text])\n",
    "    return int(clf.predict(vec)[0])\n",
    "\n",
    "for t in test_cases:\n",
    "    ft = predict_with_distilbert(fine_tuned_model, t)\n",
    "    base = predict_with_distilbert(base_model, t)\n",
    "    clf_pred = predict_with_classical(t)\n",
    "    gpt_pred = classify_with_gpt2(t)\n",
    "\n",
    "    print(f\"\\nReview: {t}\")\n",
    "    print(f\"  Fine tuned DistilBERT: {ft}\")\n",
    "    print(f\"  Base DistilBERT:       {base}\")\n",
    "    print(f\"  Classical LogReg:      {clf_pred}\")\n",
    "    print(f\"  GPT 2:                 {gpt_pred}\")\n",
    "    print(\"  (1 = positive, 0 = negative)\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
