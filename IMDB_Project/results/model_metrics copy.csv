Model,Accuracy,Precision,Recall,F1
Fine tuned DistilBERT,0.9141,0.9092706068392963,0.92,0.9146038373595785
Base DistilBERT,0.5007,0.5614035087719298,0.0064,0.01265572473798695
Classical Logistic Regression,0.9008,0.8943329397874853,0.909,0.9016068240428486
GPT 2 (subset),0.56,0.5451388888888888,0.9936708860759493,0.7040358744394619
